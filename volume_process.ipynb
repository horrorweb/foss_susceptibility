{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import cv2\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 2 to use\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import  TensorDataset, DataLoader\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "\n",
    "device = torch.device(2 if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "import scipy.io\n",
    "import cmath                \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "# import utills\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 기본 `log_dir` 은 \"runs\"이며, 여기서는 더 구체적으로 지정하였습니다\n",
    "writer = SummaryWriter('runs/experiment1')\n",
    "import nibabel as nib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pydicom as dcm\n",
    "\n",
    "import pandas as pd\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn import plotting\n",
    "from nilearn.image import concat_imgs, mean_img, resample_img\n",
    "import nilearn\n",
    "\n",
    "from utils.nifti_utils import *\n",
    "from utils.common import *\n",
    "from utils.fmri_utils_true import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ComplexConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(ComplexConv,self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.padding = padding\n",
    "\n",
    "        ## Model components\n",
    "        self.conv_re = nn.Conv2d(in_channel, out_channel, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.conv_im = nn.Conv2d(in_channel, out_channel, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        \n",
    "    def forward(self, x): # shpae of x : [batch,2,channel,axis1,axis2]\n",
    "        real = self.conv_re(x[:,0]) - self.conv_im(x[:,1])\n",
    "        imaginary = self.conv_re(x[:,1]) + self.conv_im(x[:,0])\n",
    "        output = torch.stack((real,imaginary),dim=1)\n",
    "        return output\n",
    "        \n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    ## Random Tensor for Input\n",
    "    ## shape : [batchsize,2,channel,axis1_size,axis2_size]\n",
    "    ## Below dimensions are totally random\n",
    "    x = torch.randn((10,2,3,100,100))\n",
    "    \n",
    "    # 1. Make ComplexConv Object\n",
    "    ## (in_channel, out_channel, kernel_size) parameter is required\n",
    "    complexConv = ComplexConv(3,10,(5,5))\n",
    "    \n",
    "    # 2. compute\n",
    "    y = complexConv(x)\n",
    "\n",
    "batchnorm=True\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, out_ch, start_channel=64, alpha=1, bias=False, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "        # self.inc=nn.Conv2d(n_channels, 64, kernel_size=1, padding=0, bias=bias)\n",
    "        self.inc = (DoubleConv(n_channels, start_channel, bias=bias))\n",
    "        self.down1 = (Down(start_channel, start_channel*2, bias=bias))\n",
    "        self.down2 = (Down(start_channel*2, start_channel*4, bias=bias))\n",
    "        self.down3 = (Down(start_channel*4, start_channel*8, bias=bias))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(start_channel*8, start_channel*16 // factor, bias=bias))\n",
    "        self.down5 = (Down(start_channel*16, start_channel*32 // factor, bias=bias))\n",
    "        self.up1 = (Up(start_channel*32, start_channel*16, bilinear, bias=bias))\n",
    "        self.up2 = (Up(start_channel*16, start_channel*8, bilinear, bias=bias))\n",
    "        self.up3 = (Up(start_channel*8, start_channel*4 // factor, bilinear, bias=bias))\n",
    "        self.up4 = (Up(start_channel*4, start_channel*2 // factor, bilinear, bias=bias))\n",
    "        self.up5 = (Up(start_channel*2, start_channel // factor, bilinear, bias=bias))\n",
    "        \n",
    "        self.outc = (OutConv(start_channel, out_ch, bias=False))\n",
    "        # self.outc = (DoubleConv(start_channel, out_ch, bias=bias))\n",
    "        self.alpha=alpha\n",
    "    def forward(self, x):\n",
    "        temp=x\n",
    "        x1 = self.inc(temp)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x6 = self.down5(x5)\n",
    "\n",
    "        temp = self.up1(x6, x5)\n",
    "        temp = self.up2(temp, x4)\n",
    "        temp = self.up3(temp, x3)\n",
    "        temp = self.up4(temp, x2)\n",
    "        temp = self.up5(temp, x1)\n",
    "        logits = self.outc(temp)+x\n",
    "        return logits\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels,kernel_size=3, mid_channels=None,bias=False):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        if batchnorm==True:\n",
    "            self.double_conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, padding=1, bias=bias),\n",
    "                nn.BatchNorm2d(mid_channels),\n",
    "                nn.PReLU(),\n",
    "                nn.Conv2d(mid_channels, out_channels, kernel_size=kernel_size, padding=1, bias=bias),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.PReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.double_conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, mid_channels, kernel_size=kernel_size, padding=1, bias=bias),\n",
    "                nn.PReLU(),\n",
    "                nn.Conv2d(mid_channels, out_channels, kernel_size=kernel_size, padding=1, bias=bias),\n",
    "                nn.PReLU()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bias=False):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 2, stride=2, padding=0, bias=bias),\n",
    "            DoubleConv(in_channels, out_channels, bias=bias)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=False, bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2, bias=bias)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2, bias=False)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=False):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1,bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GE epi에서 SE epi로 가는 모델. 데이터는 하나로 오버피팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters\n",
    "mod_num=80\n",
    "center_slice=104\n",
    "mask=False\n",
    "dummy_measurement_num=10\n",
    "# n=4\n",
    "epoch=100\n",
    "cutoff_percentage=0\n",
    "threshold=3\n",
    "## outputs\n",
    "np_image_list=[]\n",
    "np_mask_list=[]\n",
    "slice_scale_z_map_nonprocessed_list=[]\n",
    "slice_scale_z_map_processed_list=[]\n",
    "\n",
    "AP_cor=nib.load('/home/milab/SSD_8TB/LeeSooHyung/datasets/fmri_inhomo_test_2/2024.06.03/JKJin/Stroop/Stroop_task_HC_SE_EPI_AP.nii')\n",
    "GE_39ms=nib.load('/home/milab/SSD_8TB/LeeSooHyung/datasets/fmri_inhomo_test_2/2024.06.03/JKJin/Stroop/Stroop_task_HC_2mm.nii').get_fdata()[:,:,:]\n",
    "SE_EPI_original=AP_cor.get_fdata()[:,:,:]\n",
    "GE_EPI=GE_39ms\n",
    "GE_EPI_avg=0\n",
    "for i in range(dummy_measurement_num):\n",
    "    GE_EPI_avg=GE_EPI_avg+GE_EPI[:,:,:,i]\n",
    "GE_EPI_avg=GE_EPI_avg/dummy_measurement_num\n",
    "for slice_num in range(GE_EPI.shape[2]):\n",
    "    print(\"Slice_num:\",slice_num)\n",
    "\n",
    "    ################### MPRAGE PLOT #####################   \n",
    "    # check_img(mprage[:,:,slice_num*2],cbar=False,norm=True,rotate=True)\n",
    "    # check_img(mprage[:,:,slice_num*2+1],cbar=False,norm=True,rotate=True)\n",
    "    ##################################################### \n",
    "    \n",
    "\n",
    "    AP_mask_sliced=make_mask_sliced_direct(AP_cor,slice_num)\n",
    "    if mask==False:\n",
    "        AP_mask_sliced=copy_nii_header(np.ones(AP_mask_sliced.get_fdata().shape),AP_mask_sliced)\n",
    "    np_mask_list.append(AP_mask_sliced.get_fdata())\n",
    "    # check_img(GE_EPI_avg[:,:,slice_num])\n",
    "\n",
    "    SE_EPI=SE_EPI_original[:,:,slice_num]\n",
    "    GE_EPI=GE_EPI_avg[:,:,slice_num]\n",
    "    # print(GE_EPI.shape)\n",
    "    SE_list=[]\n",
    "    GE_list=[]\n",
    "\n",
    "    for i in range(6):\n",
    "        SE_list.append(SE_EPI)\n",
    "        GE_list.append(GE_EPI)\n",
    "    SE_EPI=np.stack(SE_list)\n",
    "    GE_EPI=np.stack(GE_list)\n",
    "\n",
    "    array_input=torch.Tensor(GE_EPI).float()\n",
    "    array_label=torch.Tensor(SE_EPI).float()\n",
    "    \n",
    "    train_input=torch.unsqueeze(array_input[:,:,:],dim=1)\n",
    "    train_label=torch.unsqueeze(array_label[:,:,:],dim=1)\n",
    "    print(train_label.shape)\n",
    "    test=GE_39ms[:,:,slice_num,10:]\n",
    "    # print(test.shape)\n",
    "    invivo_input=torch.permute(torch.unsqueeze(torch.tensor(test),dim=2),(3,2,0,1)).float()\n",
    "\n",
    "    dataset_2ch=TensorDataset(train_input\n",
    "                            ,train_label\n",
    "                            )\n",
    "\n",
    "    invivo=TensorDataset(invivo_input,\n",
    "                        invivo_input)\n",
    "\n",
    "    traindataset=DataLoader(dataset_2ch, batch_size=1, shuffle=True)\n",
    "    valdataset=DataLoader(dataset_2ch, batch_size=1, shuffle=True)\n",
    "    invivodataset=DataLoader(invivo, batch_size=1, shuffle=False)\n",
    "\n",
    "    bold_no_pre=dataset_to_tensor(invivodataset)\n",
    "    bold_no_pre=torch.unsqueeze(torch.permute(torch.squeeze(bold_no_pre),(1,2,0)),2)\n",
    "\n",
    "    model_1=UNet(2,2,64)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.memory_summary\n",
    "    model_1=model_1.to(device)\n",
    "\n",
    "    loss_function_k=torch.nn.L1Loss()\n",
    "\n",
    "    optimizer_1=optim.AdamW(model_1.parameters(), lr=0.001, weight_decay=0)\n",
    "    scheduler=optim.lr_scheduler.StepLR(optimizer_1,100,gamma=0.8)\n",
    "\n",
    "    loss_function_img=torch.nn.MSELoss()\n",
    "    norm_scale=1000\n",
    "\n",
    "    check_num=epoch\n",
    "    i=0\n",
    "    for i in range(epoch):\n",
    "            \n",
    "        total, total_loss = train_model(model_1, traindataset, optimizer_1, loss_function_k, loss_function_img, device, norm_scale, writer, epoch_number=i,noise=None, frequency_loss=True, image_loss=False,l1norm=None,tv_loss=None)\n",
    "        scheduler.step()\n",
    "        if i%check_num==check_num-1:\n",
    "            bold=testset_output(model_1,invivodataset,device,norm_scale)\n",
    "            bold_per=abs(torch.unsqueeze(torch.permute(bold,(1,2,0)),2).float())\n",
    "            np_image_list.append(bold_per.numpy())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image_list[0].shape\n",
    "np_image_array=np.stack(np_image_list,axis=2)\n",
    "np.squeeze(np_image_array).shape\n",
    "\n",
    "preprocessed_nii=copy_nii_header(np.squeeze(np_image_array),AP_cor)\n",
    "nib.save(preprocessed_nii,'2024.06.03.JKJ_stroop.nii')\n",
    "# nib.save(preprocessed_nii,'2024.06.04.KJYoon_visual.nii')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_map,data=calculate_glm(preprocessed_nii,nilearn.masking.compute_epi_mask(AP_cor),percentage=cutoff_percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSH_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
